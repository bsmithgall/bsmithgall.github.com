---
layout: book
title: "The Age of Surveillance Capitalism"
author: "Shoshana Zuboff"
rating: "4"
date_read: "2019-07-02"
---

At its most forceful, *The Age of Surveillance Capitalism* is a terrifying
description of the imperatives that drive modern corporations. Many of its
theses have the characteristics of great ideas; as soon as you read and
understand them, you don't understand how you could have thought anything else.
There are a handful of truly illuminating concepts that give a theoretical
foundation to understanding how modern technology companies are built, and what
drives them towards some of the more seemingly confusing business decisions.

Typically, I am not a fan of authors inventing language to describe novel
phenomena: often it strikes me as a technique to muddle or dodge possible
critiques. In this case, though, I think Zuboff does a good job of establishing
a descriptive language that does not create confusion unnecessarily.

One of the first ways that she does this is to dispatch of the common refrain
that "if you aren't paying for it, you are the product." Instead, she argues
that users of nominally free products are actually "raw material supply:"

> it is inaccurate to think of Google's users as its customers: there is no
> economic exchange, no price, and no profit. Nor do users function in the role
> of workers. When a capitalist hires workers and provides them with wages and
> means of production, the products that they produce belong to the capitalist
> to sell at a profit. Not so here. Users are not paid for their labor, nor do
> they operate the means of production... users are not products, but rather we
> are the sources of raw-material supply.

At first, Zuboff says, that users generated "data exhaust" was not such
a terrible issue, since that exhaust was used to improve the services, and
nothing else: 

> The fact that users needed Search about as much as Search needed users created
> a balance of power between Google and its populations. People were treated as
> ends in themselves, the subjects of a nonmarket, self-contained cycle that was
> perfectly aligned with Google’s stated mission “to organize the world's
> information, making it universally accessible and useful.”

Of course, this all comes to end during the dot-com burst, when Google was
searching to find new sources of income. At this point, they realize that they
are sitting on these untapped sources of "raw-material supply," and surveillance
capitalism as it is known today was born. 

These first few chapters describing the historical and political environments
that give rise to surveillance capitalism are well-worth reading. They are lucid
and fascinating, and end up with the creation of the surveillance capitalism
practices that we know today. They also lead to one of Zuboff's most interesting
points: surveillance firms are eventually captured by what she calls the
"extraction imperative." Any source of data that can be collected must be
collected. Eventually, this imperative leads to the surveillance leaving
computers and entering the physical world: the "internet of things" is a vast
surveillance apparatus, controlled largely by a handful of corporations.

The goal of all this, Zuboff argues, is to create what she calls "guaranteed
outcomes" for advertisers, the surveillance firms' true customers. By creating
a massive surveillance net on both the online and offline worlds, the firms can
change the behavior of their supply into something profitable for both them and
their customers:

> Eventually, surveillance capitalists discovered that the most-predictive
> behavioral data come from intervening in the state of play in order to nudge,
> coax, tune, and herd behavior toward profitable outcomes.

This is true: if you can coerce a behavior, then you can predict it quite
accurately.

Over time, these changes force us towards a "hive" which strips us of our
individuality. We lose what Zuboff calls the "right to the future tense" as our
behavior is quietly shaped by the nudges and herding of the surveillance firms.
Some of these nudges are subtle. Zuboff returns often to the Facebook study,
[published in Nature](http://fowler.ucsd.edu/massive_turnout.pdf), where
Facebook used a hidden A/B test to create a statistically significant difference
in voter turnout. There was of course no way to know that Facebook had been
engaged in that experiment until after it had finished. The nudges, though, can
also be not subtle at all. Zuboff also returns quite frequently to a discussion
of how insurance companies or loan providers could [remotely disable your
car](https://dealbook.nytimes.com/2014/09/24/miss-a-payment-good-luck-moving-that-car/)
should you miss payments.

Zuboff argues that these "nudges" force us into a stream of behavior that can be
rendered into data, understood, and sold. Due to the extraction imperative, the
sources for these nudges grow constantly, and if there is no change, then our
futures will become nullified as the battle for the human spirit is lost to the
surveillance firms.

There is a pretty deep irony to this, though. It seems pretty clear that we have
built a large surveillance apparatus both online and off. The irony comes in,
though, when you think about the state of the online advertising industry. While
it is certainly a magic money tree for the large surveillance players, the
system itself seems pretty unstable. There is [widespread][widespread]
[fraud][fraud] and [robots][robots] basically everywhere. The industry itself is
essentially an endless morass of middlemen, each of which as their own
surveillance apparatus to render and collect data about people.

![the endless morass](https://static01.nyt.com/images/2019/05/07/opinion/07warz1/3f896c5c7915498db877daffcec9044d-superJumbo.jpg?quality=90&auto=webp)

I wish that Zuboff had taken this on a bit: if we are willing to build this
gigantic surveillance infrastructure for these lackluster results, then what
kind of infrastructure would we build if we were better-able to accurately
create profiles of people? Get better guaranteed outcomes?

Zuboff ends her conclusion with some notes about what it would take to climb
back out of the pit and reclaim our humanity. She dwells a bit on the
possibility that perhaps we are unable to. Maybe we are too broken, or unable to
handle the responsibility of forging our own identities. Drawing from Hannah
Arendt's [Origins of Totalitarianism][totalitarianism], she imagines a future
where, thoroughly defeated, we simple give in to the hive. To avoid this future,
though, it's up to all of us. We must realize and object to the state of things
to recognize the "dispossession cycle" and reclaim our humanity.

[widespread]: https://www.nytimes.com/2016/12/20/technology/forgers-use-fake-web-users-to-steal-real-ad-revenue.html
[fraud]: https://www.nytimes.com/interactive/2018/08/11/technology/youtube-fake-view-sellers.html
[robots]: https://www.nytimes.com/interactive/2018/01/27/technology/social-media-bots.html
[totalitarianism]: https://en.wikipedia.org/wiki/The_Origins_of_Totalitarianism
